{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "a4103022",
      "metadata": {
        "collapsed": true,
        "id": "a4103022"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy\n",
        "!pip install spacy-transformers\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "15908c19",
      "metadata": {
        "id": "15908c19"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from spacy import displacy\n",
        "import sys, fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6887f800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6887f800",
        "outputId": "819a30b0-d8c1-4316-e4bb-4b9c9d8bd367"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "910d1ce8",
      "metadata": {
        "id": "910d1ce8"
      },
      "outputs": [],
      "source": [
        "# Loading JSON file (dataset)\n",
        "cv_data = json.load(open(\"CV-Parsing-using-Spacy-3/data/training/train_data.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "0b707c21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b707c21",
        "outputId": "5c32e844-9ab3-43da-d56d-4e03b0985868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "len(cv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "b3fce0ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3fce0ab",
        "outputId": "949ed02d-fb3b-456b-af09-d3a79cc5d747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "# Setting up configuration file\n",
        "!python -m spacy init fill-config CV-Parsing-using-Spacy-3/data/training/base_config.cfg CV-Parsing-using-Spacy-3/data/training/config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "30ab5f1a",
      "metadata": {
        "id": "30ab5f1a"
      },
      "outputs": [],
      "source": [
        "def get_spacy_doc(file, data):\n",
        "    nlp = spacy.blank('en')\n",
        "    db = DocBin()\n",
        "    \n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp.make_doc(text)\n",
        "        annot = annot['entities']\n",
        "        \n",
        "        ents = []\n",
        "        entity_indices = []\n",
        "        \n",
        "        # below code will help to identify if there is any overlapping entity. If yes, then we'll keep only 1st entity and skip other\n",
        "        for start, end , label in annot:\n",
        "            skip_entitiy = False\n",
        "            for idx in range(start, end):\n",
        "                if idx in entity_indices:\n",
        "                    skip_entitiy = True\n",
        "                    break\n",
        "            if skip_entitiy:\n",
        "                continue\n",
        "                \n",
        "                \n",
        "            entity_indices = entity_indices + list(range(start, end))\n",
        "            \n",
        "            #Getting span of data\n",
        "            try:\n",
        "                span = doc.char_span(start, end, label = label, alignment_mode='strict')\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # If the given index span has no value the we'll add those data into error.txt file\n",
        "            if span is None:\n",
        "                err_data = str([start, end]) + \"    \" + str(text) +'\\n'\n",
        "                file.write(err_data)\n",
        "                \n",
        "            else:\n",
        "                ents.append(span)\n",
        "                \n",
        "                \n",
        "        try:\n",
        "          # Setting up custom entities and adding it to docbin object\n",
        "            doc.ents = ents\n",
        "            db.add(doc)\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    return db\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "bd617e39",
      "metadata": {
        "id": "bd617e39"
      },
      "outputs": [],
      "source": [
        "# Creating train and test dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_data, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "e293ac5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e293ac5c",
        "outputId": "a2332f52-0d35-41f8-c2d3-686400c0386f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "len(train), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "ca7f2196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7f2196",
        "outputId": "8ef2c7e8-04eb-4936-863f-80735388b8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [00:01<00:00, 91.07it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 80.34it/s]\n"
          ]
        }
      ],
      "source": [
        "file = open('error.txt', 'w', encoding='utf-8')\n",
        "\n",
        "#Extracting and saving spacy file to the disk for training purpose\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "43476a18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43476a18",
        "outputId": "fa17c2b7-bb43-4b13-f163-0bf0e569b8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-15 14:21:11,829] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-15 14:21:11,840] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-15 14:21:11,844] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-15 14:21:11,845] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-15 14:21:20,296] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        8898.86   1549.18    0.54    0.28    9.15    0.01\n",
            "  3     200      231487.72  75928.46   14.27   15.98   12.90    0.14\n",
            "  6     400       40334.34  31942.48   32.07   23.04   52.70    0.32\n",
            " 10     600        9575.79  27657.92   24.40   19.00   34.12    0.24\n",
            " 13     800        5734.78  26473.72   29.29   22.29   42.72    0.29\n",
            " 17    1000        3525.55  24841.00   28.17   21.33   41.47    0.28\n",
            " 20    1200       11424.82  23532.61   55.66   51.66   60.33    0.56\n",
            " 24    1400        1774.26  22536.33   56.02   61.67   51.32    0.56\n",
            " 27    1600        1404.35  20765.58   54.21   67.08   45.49    0.54\n",
            " 31    1800         739.47  20870.38   60.38   66.84   55.06    0.60\n",
            " 34    2000        1658.02  18790.31   55.22   68.66   46.19    0.55\n",
            " 37    2200        1133.75  18773.19   58.94   63.96   54.65    0.59\n",
            " 41    2400         558.47  17028.83   57.70   68.85   49.65    0.58\n",
            " 44    2600         425.23  16310.53   58.98   65.65   53.54    0.59\n",
            " 48    2800         461.48  14921.22   51.90   68.56   41.75    0.52\n",
            " 51    3000         528.32  13188.66   58.73   69.92   50.62    0.59\n",
            " 55    3200         401.88  11833.05   60.42   63.41   57.70    0.60\n",
            " 58    3400        7016.83   9781.68   53.04   72.71   41.75    0.53\n",
            " 62    3600         627.87   8280.82   55.86   60.88   51.60    0.56\n",
            " 65    3800         416.79   6011.28   54.79   71.59   44.38    0.55\n",
            " 68    4000         604.47   4762.06   58.32   64.86   52.98    0.58\n",
            " 72    4200         597.61   3150.65   59.13   65.82   53.68    0.59\n",
            " 75    4400         600.02   2264.76   59.63   70.38   51.73    0.60\n",
            " 79    4600         681.83   1487.23   54.62   68.33   45.49    0.55\n",
            " 82    4800         735.37    987.24   56.48   73.39   45.91    0.56\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ],
      "source": [
        "# Training the custom spacy NER model\n",
        "!python -m spacy train CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "41de8d3b",
      "metadata": {
        "id": "41de8d3b"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Test"
      ],
      "metadata": {
        "id": "OmA9KBqwg0CU"
      },
      "id": "OmA9KBqwg0CU"
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')  # Loading best model"
      ],
      "metadata": {
        "id": "1H3kRcSkg2NQ"
      },
      "id": "1H3kRcSkg2NQ",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.get_pipe(\"ner\").labels  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBVdOl7Jjv8S",
        "outputId": "028af6e3-8965-460b-a5d4-e24d333ad4fa"
      },
      "id": "eBVdOl7Jjv8S",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('College Name',\n",
              " 'Companies worked at',\n",
              " 'Degree',\n",
              " 'Designation',\n",
              " 'Email Address',\n",
              " 'Graduation Year',\n",
              " 'Location',\n",
              " 'Name',\n",
              " 'Skills',\n",
              " 'UNKNOWN',\n",
              " 'Years of Experience')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up colors for custom entities\n",
        "colors = {\n",
        "    'College Name' : '#E6B0AA',\n",
        "    'Companies worked at' : '#AF7AC5', \n",
        "    'Degree' : '#5499C7', \n",
        "    'Designation' : '#5DADE2', \n",
        "    'Email Addresss' : '#48C9B0', \n",
        "    'Graduation Year' : '#73C6B6', \n",
        "    'Location' : '#2ECC71', \n",
        "    'Name' : '#F9E79F', \n",
        "    'Skills' : '#EB984E', \n",
        "    'UNKNOWN' : '#D35400', \n",
        "    'Years of Experience' : '#839192'}\n",
        "\n",
        "\n",
        "options = {\"ents\": list(nlp.get_pipe(\"ner\").labels), \"colors\": colors}"
      ],
      "metadata": {
        "id": "K3oCmLEAhkIj"
      },
      "id": "K3oCmLEAhkIj",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading resume \n",
        "fname = '/content/CV-Parsing-using-Spacy-3/data/test/Aish_Resume.pdf'\n",
        "doc = fitz.open(fname)"
      ],
      "metadata": {
        "id": "Rk3FFc8NiLmr"
      },
      "id": "Rk3FFc8NiLmr",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting resume into text\n",
        "text = [page.get_text() for page in doc][0].strip().split()\n",
        "text = \" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "yn55IwEQiida",
        "outputId": "70b5272a-7bfa-4b59-e31e-26308e1c83c9"
      },
      "id": "yn55IwEQiida",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Aishwarya Pachaiyappan Data Scientist Data scientist with Two years of experience in analysing large datasets and coming up with data-driven insights .Proﬁcient in Predictive modelling,data processing and data mining algorithms.I'm a energetic, and geeky individual whose desire to learn is endless aishwaryayamunap02@gmail.com 9677227289 Chennai, India WORK EXPERIENCE Data Scientist Infosys Limited 06/2019 - Present, Chennai, India 3years of experience as Engineer -Industrial IT • Developed Classiﬁcation algorithm to provide result based on classiﬁcation from large set of data and developed NLP algorithm to provide suggestion based on similarity check Knowledge in Creating Models using Python for Data Prediction and Classiﬁcation using libraries such as NumPy, Pandas, Matplotlib and Scikit learn Experience in database management and Microsoft Dynamics 365 CRM Contact : +91 9677227289 EDUCATION Bachelor of Computer Application Madaras Christian college 06/2016 - 05/2019, Chennai,India PGD in AI & ML University of Hyderabad 02/2020 - 02/2021, Chennai,India Excelled in coursework & Completed a thesis project (GitHub , Medium blog) loan default - prediction. (Graduated with Distinction) Certiﬁed on Advanced Digital- Marketing FITA Academy B.Ed. in Hindi Pandit Hindi Prachar Saba SKILLS Technical skills => Data Science, Linear & Logistics Regression, Naive Bayes, KNN, Decision Tree, Random Forest, GBDT, XGBoost, SVM, LSTM, MS Dynamics CRM, Data visualization tools, Python, SQL, etc Area => Machine Learning, Data Analysis, NLP , Sentiment Analysis, Document Classiﬁcation, Tokenization, Feature Engineering, Model Training, Feature Selection, Validation, Cleansing, Statistical & Predictive analysis. Programming languages and tools => Python (Numpy, Pandas, Scipy, Scikit-learn, Keras, Matplotlib, Seaborn, NLTK), Microsoft Dynamics 365 CRM, SQL Server PROJECTS PROFILE Loan Default Prediction (02/2020 - 02/2021) https://github.com/AishwaryaPachaiyapppan/Loan_default_predictio n Objective: Banking | Help the bank to sanction or reject the loan based on whole users’ data. Analysis: • Did univariate and Bivariate analysis, removed outliers, extract important features using statistical Knowledge • Handling missing values using techniques like median imputation and mode • Encoding non-numerical features using techniques like one-hot encoding Handling outliers using inter quartile range and boxplots Balancing data using algorithms like SMOTE. Random Sampling Model Built: Used Machine Learning knowledge to train and validate models like logistic regression, Random Forest, AdaBoost Classiﬁer, Naive Bayes. Able to leverage statistical expertise to decide on key metric to be used Used Stream lit to deploy ﬁnal model that has better performance. ACHIEVEMENTS Outstanding Achievement Award, Best Customer satisfaction Award LANGUAGES Tamil Native or Bilingual Proﬁciency English Full Professional Proﬁciency CERTIFICATION Infosys Certiﬁed Python Associate Achievements/Tasks Courses\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text into spacy doc and then printing the extracted entities\n",
        "\n",
        "doc = nlp(text)\n",
        "text_list = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.text not in text_list:\n",
        "    print(ent.text, '\\t\\t\\t\\t\\t', ent.label_)\n",
        "    text_list.append(ent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bb2gmd6jNGz",
        "outputId": "481cd72c-b16e-4b30-f9cf-0e1f74f94ee0"
      },
      "id": "2Bb2gmd6jNGz",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aishwarya Pachaiyappan \t\t\t\t\t Name\n",
            "Data Scientist \t\t\t\t\t Designation\n",
            "Data scientist \t\t\t\t\t Designation\n",
            "Two years \t\t\t\t\t Years of Experience\n",
            "Infosys \t\t\t\t\t Companies worked at\n",
            "Bachelor of Computer Application \t\t\t\t\t Degree\n",
            "Madaras Christian college \t\t\t\t\t College Name\n",
            "B.Ed. in Hindi Pandit Hindi Prachar \t\t\t\t\t Degree\n",
            "Technical skills => Data Science, Linear & Logistics Regression, Naive Bayes, KNN, Decision Tree, Random Forest, GBDT, XGBoost, SVM, LSTM, MS Dynamics CRM, Data visualization tools, Python, SQL, etc Area => Machine Learning, Data Analysis, NLP , Sentiment Analysis, Document Classiﬁcation, Tokenization, Feature Engineering, Model Training, Feature Selection, Validation, Cleansing, Statistical & Predictive analysis. \t\t\t\t\t Skills\n",
            "Loan Default Prediction (02/2020 - 02/2021) \t\t\t\t\t Skills\n",
            "Infosys Certiﬁed \t\t\t\t\t Companies worked at\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter = True, options = options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "zSQaAvjPjrsa",
        "outputId": "c38c21b8-e15a-4797-80b2-540181703a3d"
      },
      "id": "zSQaAvjPjrsa",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #F9E79F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Aishwarya Pachaiyappan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Name</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #5DADE2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Data Scientist\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Designation</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #5DADE2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Data scientist\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Designation</span>\n",
              "</mark>\n",
              " with \n",
              "<mark class=\"entity\" style=\"background: #839192; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Years of Experience</span>\n",
              "</mark>\n",
              " of experience in analysing large datasets and coming up with data-driven insights .Proﬁcient in Predictive modelling,data processing and data mining algorithms.I'm a energetic, and geeky individual whose desire to learn is endless aishwaryayamunap02@gmail.com 9677227289 Chennai, India WORK EXPERIENCE \n",
              "<mark class=\"entity\" style=\"background: #5DADE2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Data Scientist\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Designation</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Infosys\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Limited 06/2019 - Present, Chennai, India 3years of experience as Engineer -Industrial IT • Developed Classiﬁcation algorithm to provide result based on classiﬁcation from large set of data and developed NLP algorithm to provide suggestion based on similarity check Knowledge in Creating Models using Python for Data Prediction and Classiﬁcation using libraries such as NumPy, Pandas, Matplotlib and Scikit learn Experience in database management and Microsoft Dynamics 365 CRM Contact : +91 9677227289 EDUCATION \n",
              "<mark class=\"entity\" style=\"background: #5499C7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bachelor of Computer Application\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Degree</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #E6B0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Madaras Christian college\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">College Name</span>\n",
              "</mark>\n",
              " 06/2016 - 05/2019, Chennai,India PGD in AI &amp; ML University of Hyderabad 02/2020 - 02/2021, Chennai,India Excelled in coursework &amp; Completed a thesis project (GitHub , Medium blog) loan default - prediction. (Graduated with Distinction) Certiﬁed on Advanced Digital- Marketing FITA Academy \n",
              "<mark class=\"entity\" style=\"background: #5499C7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    B.Ed. in Hindi Pandit Hindi Prachar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Degree</span>\n",
              "</mark>\n",
              " Saba SKILLS \n",
              "<mark class=\"entity\" style=\"background: #EB984E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Technical skills =&gt; Data Science, Linear &amp; Logistics Regression, Naive Bayes, KNN, Decision Tree, Random Forest, GBDT, XGBoost, SVM, LSTM, MS Dynamics CRM, Data visualization tools, Python, SQL, etc Area =&gt; Machine Learning, Data Analysis, NLP , Sentiment Analysis, Document Classiﬁcation, Tokenization, Feature Engineering, Model Training, Feature Selection, Validation, Cleansing, Statistical &amp; Predictive analysis.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
              "</mark>\n",
              " Programming languages and tools =&gt; Python (Numpy, Pandas, Scipy, Scikit-learn, Keras, Matplotlib, Seaborn, NLTK), Microsoft Dynamics 365 CRM, SQL Server PROJECTS PROFILE \n",
              "<mark class=\"entity\" style=\"background: #EB984E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Loan Default Prediction (02/2020 - 02/2021)\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
              "</mark>\n",
              " https://github.com/AishwaryaPachaiyapppan/Loan_default_predictio n Objective: Banking | Help the bank to sanction or reject the loan based on whole users’ data. Analysis: • Did univariate and Bivariate analysis, removed outliers, extract important features using statistical Knowledge • Handling missing values using techniques like median imputation and mode • Encoding non-numerical features using techniques like one-hot encoding Handling outliers using inter quartile range and boxplots Balancing data using algorithms like SMOTE. Random Sampling Model Built: Used Machine Learning knowledge to train and validate models like logistic regression, Random Forest, AdaBoost Classiﬁer, Naive Bayes. Able to leverage statistical expertise to decide on key metric to be used Used Stream lit to deploy ﬁnal model that has better performance. ACHIEVEMENTS Outstanding Achievement Award, Best Customer satisfaction Award LANGUAGES Tamil Native or Bilingual Proﬁciency English Full Professional Proﬁciency CERTIFICATION \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Infosys Certiﬁed\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Python Associate Achievements/Tasks Courses</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}